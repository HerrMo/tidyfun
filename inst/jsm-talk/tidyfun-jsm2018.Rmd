---
title: '**`tidyfun`**: Tidy Functional Data'
subtitle: 'A new framework for representing and working with function-valued data in **`R`**'
date: "JSM 2018"
author: 
    - "Fabian Scheipl$^1$"
    - "Arthur Jeff Goldsmith$^2$"
institute: 
    - "$^1$: Dept. of Statistics, LMU Munich"
    - "$^2$: Columbia University Mailman School of Public Health"
output: 
  beamer_presentation: 
    keep_tex: yes 
    includes:
      in_header: header.tex
    highlight: pygments
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  size = 'footnotesize',
  cache = TRUE,
  fig.width = 8, fig.height = 5.5, 
  warning = FALSE, message = FALSE)

library(tidyverse)
library(refund)
library(ggplot2)
library(patchwork)
library(viridisLite)
theme_set(theme_minimal())
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

try(devtools::load_all("~/fda/tidyfun"))
try(devtools::load_all("~/Work/fda/tidyfun"))

pal_5 = viridis(7)[-(1:2)]
```

```{r load, echo=FALSE}
dti = with(refund::DTI, 
  data.frame(id = ID, sex = sex, 
    case = factor(ifelse(case, "MS", "control")))) %>% as.tbl %>% 
        mutate(cca = tfd(DTI$cca, seq(0,1, l = 93), signif = 2) %>%
                     tfd(arg = seq(0,1,l = 93)),
               rcst = tfd(DTI$rcst, seq(0, 1, l = 55), signif = 3))
set.seed(1221)
ex_data = dti$cca[1:5, seq(0, 1, l = 93), interpolate = TRUE]
rownames(ex_data) = LETTERS[1:5]
ex = tfd(ex_data, signif = 2)
```

# 

## `tidyfun`

The goal of `tidyfun` is to provide a `tidyverse`-compliant, accessible and well-documented way to deal with functional data in `R`, 
specifically for data wrangling and exploratory analysis.

`tidyfun` provides:  

- new `R` data types for representing functional data: `tfd` & `tfb`

- arithmetic operators, descriptive statistics and graphics functions for such data

- `tidyverse`-verbs for handling functional data **inside** data frames.

# `tf`-Class: Definition

##  `tf`-class

**`tf`** is a new data type for (vectors of) functional data: 

- abstract superclass for functional data 
    - as (argument, value)-tuples: subclass **`tfd`**, also irregular or sparse
    - or in basis representation: subclass **`tfb`**
    
- basically, a `list` of numeric vectors  
  (... since `list`s work well as columns of data frames ...)

- with additional attributes that help define *function-like* behavior:
    - how to **evaluate** the given 'functions' for new arguments
    - their **domain** 
    - the **resolution** of the argument values

## Example Data

```{r, ex-fig, echo = FALSE, out.height = '.45\\textheight', fig.width = 6, fig.height = 4}
plot(ex,  xlim = c(-0.15, 1), col = pal_5)
text(x = -.1, y = ex[,0.07], labels = names(ex), col = pal_5)
```

```{r}
ex
```

## Example Data

```{r}
dti
```

## **`tf`** subclass: **`tfd`**

**`tfd`** objects contain "raw" functional data: 

 - represented as a list of **`evaluations`** $f_i(t)|_{t=\boldmath{t'}}$ and corresponding **`arg`**-vector(s) $\boldmath{t'}$
 - has a **`domain`**:  a range of valid **`arg`**s.

```{r}
ex %>% evaluations() %>% str
ex %>% arg() %>% str
ex %>% domain() 
```

## **`tf`** subclass: **`tfd`**

- each **`tfd`**-vector contains an **`evaluator`** function that defines how to inter-/extrapolate `evaluations` between `arg`s (and remembers results of previous calls)

```{r}
evaluator(ex) %>% str
evaluator(ex) = approx_spline 
```

## **`tf`** subclass: **`tfd`** 

- **`tfd`** has subclasses for regular data with a common grid and irregular or sparse data.

```{r, out.height = '.30\\textheight', fig.width = 6, fig.height = 4.5}
dti$rcst[1:2]
dti$rcst[1:2] %>% arg() %>% str
dti$rcst[1:2] %>% plot(pch = "x", col = viridis(2))
```

## **`tf`** subclass: **`tfb`**

Functional data in basis representation: 

 - represented as a list of **`coefficients`** and a common **`basis_matrix`** of basis function evaluations on a vector of `arg`-values.
 - contains a **`basis`** function that defines how to compute the basis for new **`arg`**s and how to differentiate/integrate.
 - (internal) flavors: **`mgcv`**-spline bases and FPCs (wavelets to be added)
- significant memory and time savings:
```{r}
refund::DTI$cca %>% object.size() %>% print(units = "Kb")
dti$cca %>% object.size() %>% print(units = "Kb")
dti$cca %>% tfb(verbose = FALSE) %>% object.size() %>% print(units = "Kb")
```

## **`tf`** subclass: **`tfb`** spline basis

- accepts all arguments of `mgcv`'s `s()`-syntax 
- either does a penalized fit with (GCV-based) function-specific smoothing or unpenalized.

```{r, message = TRUE}
ex_b = ex %>% tfb(); ex_b[1:2]
ex[1:2] %>% tfb(bs = "tp", k = 55)
```

## **`tf`** subclass: **`tfb`** spline basis

```{r, eval = FALSE}
plot(ex, alpha = 1)
plot(ex_b, col = "red")
lines(ex %>% tfb(penalized = FALSE, k = 30), col = "blue")
```
```{r, echo = FALSE, results = 'hide', out.height = '.4\\textheight', fig.width = 8, fig.height = 4}
layout(t(1:2))
plot(ex, alpha = 1)
plot(ex_b, col = "red")
lines(tfb(ex, penalized = FALSE, k = 30), col = "blue")
```

## **`tf`** subclass: **`tfb`** FPC-based

- uses either 
    - simple unregularized SVD of the data matrix ("`smooth = FALSE`")
    - or smoothed covariance estimate from `refund::fpca.sc`
- corresponding FPC basis and mean function saved as `tfd`-object
- observed functions are linear combinations of those.

```{r}
(ex %>% tfb_fpc(smooth = FALSE, pve = .999))
(ex %>% tfb_fpc(pve = .95))
```

## **`tf`** subclass: **`tfb`** FPC-based

```{r, eval = FALSE}
plot(ex, pch = ".")
plot(ex  %>% tfb_fpc(smooth = FALSE, pve = .999), col = "red")
lines(ex %>% tfb_fpc(pve = .95), col = "blue")
```

```{r, echo = FALSE, results = 'hide', out.height = '.4\\textheight', fig.width = 8, fig.height = 4}
layout(t(1:2))
plot(ex, alpha = 1)
plot(ex  %>% tfb_fpc(smooth = FALSE, pve = .999), col = "red", ylab = "tfb_fpc(ex)")
lines(ex %>% tfb_fpc(pve = .95), col = "blue")
```

# `tf`-Class: Methods

## Subset & subassign

```{r}
ex[1:2]
ex[1:2] = ex[2:1]
ex
```


## Evaluate

```{r, warning  = FALSE}
ex[1:2, seq(0, 1, l = 3)]
ex["B", seq(0, .15, l = 3), interpolate = FALSE]
ex[1:2, seq(0, 1, l = 2), matrix = FALSE] %>% str
```

## Compare & compute

```{r, echo = FALSE}
n_ex = names(ex)
ex = unname(ex)
```

```{r}
ex[1] + ex[1] == 2 * ex[1]
log(exp(ex[2])) == ex[2]
ex - (2:-2) != ex 
```

```{r, echo = FALSE}
names(ex) = n_ex
```

## Summarize 

```{r}
c(mean = mean(ex), sd = sd(ex))

depth(ex) ## Modified Band-2 Depth (Ã  la Sun/Genton/Nychka, 2012), others to come.
median(ex) == ex[which.max(depth(ex))]
```

## (Simple, local) smoothing

```{r, echo = FALSE, fig.height = 4.5}
layout(t(1:3))
plot(ex, alpha = .2, ylab = "lowess")
lines(smooth(ex, "lowess"), col = pal_5)
plot(ex, alpha = .2, ylab = "rolling median (k=5)")
lines(smooth(ex, "rollmedian", k = 5), col = pal_5)
plot(ex, alpha = .2, ylab = "Savitzky-Golay (quartic, 11 steps)")
lines(smooth(ex, "savgol", fl = 11), col = pal_5)
```
```{r, eval  = FALSE}
ex %>% smooth("lowess") %>% plot
ex %>% smooth("rollmedian", k = 5) %>% plot
ex %>% smooth("savgol", fl = 11) %>% plot
```

## Differentiate & integrate

```{r, echo = FALSE, fig.height = 4.5}
layout(t(1:3))
plot(ex, col = pal_5)
plot(deriv(smooth(tfd(ex, signif = 4))), col = pal_5, ylab = "deriv(smooth(ex))")
plot(integrate(ex, definite = FALSE), col = pal_5)
```
```{r, eval  = FALSE}
ex %>% plot
ex %>% smooth() %>% deriv() %>% plot
ex %>% integrate(definite = FALSE) %>% plot
```
\vskip -1em
```{r}
ex %>% integrate()
```

## Query

Find `arg`uments $t$ satisfying a condition on `value` $f(t)$ (and `arg`ument $t$):

```{r}
ex %>% anywhere(value > .65)
ex[1:2] %>% where(value > .6, "all")
ex[2] %>% where(value > .6, "range")
ex %>% where(value > .6 & arg > .5, "first")
```

## Zoom & query

```{r, ex-fig2, echo = FALSE, out.height = '.35\\textheight', fig.width = 6.5, fig.height = 4}
plot(ex,  xlim = c(-0.15, 1), col = pal_5, lwd = 2)
text(x = -.1, y = ex[,0.07], labels = names(ex), col = pal_5, cex = 1.5)
lines(median(ex), col = pal_5[3], lwd = 4)
```

```{r}
ex %>% where(value == max(value), "first")
zoom(ex[c("A", "D")], .5, 1) %>% where(value == max(value), "first")
zoom(ex, 0.2, 0.6) %>% anywhere(value <= median(ex)[,arg])
```

## Convert & construct

to & from list, matrix or data frame with `"id"`,`"arg"`,`"value"`-columns:

```{r}
ex_matrix = ex %>% as.matrix(); ex_matrix[1:2, 1:3]
ex_df = ex %>% as.data.frame(); str(ex_df)
ex_matrix[1:2, ] %>% tfd()
tfd(ex_df) == tfd(ex_matrix)
```

## Visualize: `base` 

```{r ex-fig3,  out.height = '.35\\textheight', fig.width = 8, fig.height = 4}
layout(t(1:2))
plot(ex, type = "spaghetti"); lines(c(median(ex), mean(ex)), col = c(2, 4))
plot(ex, type = "lasagna", col = viridis(50))
```

## Visualize: `ggplot2`

New `geom`s with a **`tf`**-aesthetic for functional data:

- **`geom_spaghetti`** for lines
- **`geom_meatballs`**  for (lines &) points
- **`geom_lasagna`** with an **`order`**-aesthetic to sort the lasagna layers

## Visualize: `ggplot2`

```{r, eval = FALSE}
ggplot(dti, aes(tf = cca, col = case)) +
  geom_spaghetti() + facet_wrap(~ sex)
```

```{r, dti-fig1, echo = FALSE, out.height = '.7\\textheight', fig.width = 12, fig.height = 7}
ggplot(dti) + 
  geom_spaghetti(aes(tf = cca, col = case, alpha = .2 + .4*(case == "control"))) + facet_wrap(~ sex) + scale_alpha(guide = 'none', range = c(.2, .4))
```

## Visualize: `ggplot2`

```{r, eval = FALSE}
ggplot(dti, aes(tf = cca, order = integrate(cca, definite = TRUE))) + 
  geom_lasagna() + facet_wrap(~ case)
```
```{r, dti-fig2, echo = FALSE, out.height = '.7\\textheight', fig.width = 12, fig.height = 7}  
ggplot(dti[1:100,], aes(tf = cca, order = integrate(cca, definite = TRUE))) + 
  geom_lasagna(size = 2.5) + theme(axis.text.y = element_text(size = 6)) + 
    facet_wrap(~ case, ncol = 2, scales = "free")
```

# Wrangling `tf`s inside data frames

## Wrangling `tf`s inside data frames: `dplyr`

All `dplyr` verbs work well with `tf`-columns - for example:

```{r, dplyr}
# group-wise functional means:
dti %>% group_by(case, sex) %>% summarize(mean_rcst = mean(rcst, na.rm = TRUE)) %>% ungroup

# which subjects go below cca = .26:
dti %>% filter(anywhere(cca, value < .26))

# center & scale: 
dti %>% mutate(cca = tfb(cca), cca_z = (cca - mean(cca))/sd(cca)) %>% glimpse
```

## Wrangling `tf`s inside data frames: `tidyr`

`tidyfun` provides variants of `tidyr`-verbs to reshape and reformat functional data while keeping it in sync with other covariates:

```{r, tidyr}
dti_wide = dti %>% tf_spread(cca); dti_wide[, 1:10] %>% glimpse()  
dti_wide %>% tf_gather(matches("cca_")) %>% glimpse

dti_long = dti %>% tf_unnest(cca); dti_long %>% glimpse()  
dti_long %>% tf_nest(matches("cca_"), id = id, arg = arg)  
```



## Outlook

  - registering/warping should be mostly easy, just overwrite `arg` (or wrap warping around `evaluator`...?)
  - extensions for multivariate and image data (will be hard)
  - integration with renovated `refund` for modeling etc.

##  ISSUES:

  - lots of `tibblyverse` adjustments still needed (no grouped operations possible ATM, no pretty printing)
  - is `signif_argvals` reasonable?
  - no `S4` means no multiple inheritance for orthogonal implementation of aspects "representation" and "function properties" like monotonous or strictly positive functions in basis or raw data representation.
  - more issues: [https://github.com/fabian-s/tidyfun/issues]
-->
